# Pablo Mena's project portfolio
List of projects completed in the field of Data Science and its various subfields.

| Project field/year | Project name | Description              | Contributions                | Stack and methods | 
|--- |--- |------------------------- |------------------------------ |--- |
|  |  |  |  | Предложения CASE (WHEN, THEN), Агрегатные функции (EXTRACT, SUM, ROUND), Функции фильтрации (WHERE, GROUP BY, ORDER BY) |
| Machine Learning/2023 | [Assessing Customer Churn Using Machine Learning](https://github.com/PMenaM/Projects/blob/main/Assessing%20Customer%20Churn%20Using%20Machine%20Learning%20(Jupyter%20Notebook)/Assessing%20Customer%20Churn%20Using%20Machine%20Learning%20(Jupyter%20Notebook).ipynb) | Использование Pandas и машинного обучения для изучения наборов данных ведущих индийских телекоммуникационных компаний, выявления демографических моделей и моделей использования. Прогнозирование удержания клиентов, объединение анализа данных и прогнозного моделирования. |  | Pandas, Sklearn, машинное обучение, анализ данных, предварительная обработка, создание экземпляров, StandardScaler, обучение, подгонка, train_test_split, проверка, прогнозирование, LogisticRegression, RandomForestClassifier, оценка, classification_report, confusion_matrix |
| AI - Prompt Engineering/2023 | [OpenAI API for Tourism](https://github.com/PMenaM/Projects/blob/main/OpenAI%20API%20for%20Tourism%20(Jupyter%20Notebook)/Planning%20a%20Trip%20to%20Paris%20with%20the%20OpenAI%20API.ipynb) | Использование возможностей языковой обработки OpenAI для интеллектуального ответа на заранее заданные вопросы, связанные с поездками, и предоставления индивидуальных рекомендаций для знакомства с Парижем. |  | Искусственный Интеллект, OpenAI API, Prompt engineering, циклы for, извлечение признаков, списки словарей |
| Computer Vision/2023 | [Sign Language Recognition with Keras](https://github.com/PMenaM/Projects/blob/main/Sign%20Language%20Recognition%20with%20Keras%20(Jupyter%20notebook)/Sign%20Language%20Recognition%20with%20Keras%20(Jupyter%20notebook).ipynb) | Построение сверточной нейронной сети (CNN) для классификации изображений букв языка жестов. После загрузки, проверки и предварительной обработки данных сеть обучается, и ее производительность проверяется на соответствие ее точности при предсказании букв языка жестов из изображений. |  | Классификация изображений, Tensorflow/Keras, Numpy (argmax, where), Matplotlib, Convolutional Neural Networks (CNN), Conv2D, MaxPooling2D, Flatten, Dense, Sequential, compile, to_categorical, fit, evaluate, predict |
| NLP/2023 | [Topic Trend Analysis](https://github.com/PMenaM/Projects-en-/blob/main/Topic%20Trend%20Analysis%20(Jupyter%20Notebook)/Topic%20Trend%20Analysis%20(Jupyter%20Notebook).ipynb) | Using NLP topic recognition techniques in a collection of research papers from Neural Information Processing Systems (NIPS) conferences spanning 10 years. The goal of this project is to find out which topics have become more trendy, so the company can analyse them and adopt the most suitable state-of-the-art methods for their industrial processes and services.                                                                            | A major mining company was able to implement a deep learning algorithm for image detection. Increasing accuracy in material extraction, safety, and energy consumption, the company increased their KPI over a 20%.                                                                                                                                                           | Machine Learning, NLP, Topic recognition, Pandas, Numpy, Matplotlib, data pre-processing, Histogram, Regular expression (regex), WordCloud, CountVectorizer, Latent Dirichlet Allocation (LDA) |
| NLP/2023 | [Tweet Classifier](https://github.com/PMenaM/Projects-en-/blob/main/Tweet%20Classifier%20(Jupyter%20Notebook)/Tweet%20Classifier%20(Jupyter%20Notebook).ipynb) | Building an ML classification model using NLP methods for text classification and analysis. The classified data corresponds to tweets written by two North American politicians. The goal of the model is to accurately classify whether a tweet was written by one politician or the other based on the tweet's content. The model achieved 90% of accuracy.                                    |   | NLP, Machine Learning, Numpy, CountVectorizer, TfidfVectorizer, train_test_split, MultinomialNB, LinearSVC, sklearn_metrics, confusion_matrix |
| SQL/2023 | [Analyzing Unicorn Companies](https://github.com/PMenaM/Projects-en-/blob/main/Analyzing%20Unicorn%20Companies%20(Jupyter%20Notebook)/Analyzing%20Unicorn%20Companies%20(Jupyter%20Notebook).ipynb) | Information analysis about unicorn companies worth over $1 billion using a PostgreSQL database. The output table offered clear and accurate information on which industries have the highest average valuation, allowing us to determine how many new unicorns have been produced annually between 2019 and 2021.                                                                                                                      | Performed exploratory data analysis and used a timestamp method inside a CTE for extracting data from three specific years. Used filtering clauses for extracting number, year, and average values of companies, and added a join operator for merging this data. Used aggregate functions to convert and round values. Sorted the results by year and number in descending order.                                                                                                                                                                                    | Data analysis, Aggregate functions (COUNT, AVG), Join operations (INNER JOIN), Filtering clauses (WHERE, GROUP BY, ORDER BY, LIMIT, EXTRACT), Subqueries, CTE |
| SQL/2023 | [Optimizing Online Sports Retail Revenue](https://github.com/PMenaM/Projects-en-/blob/main/Optimizing%20Online%20Sports%20Retail%20Revenue%20(Jupyter%20Notebook).ipynb) | Analysis of product data for an online sports retail company. Working with numeric, string, and timestamp data on pricing and revenue, ratings, reviews, descriptions, and website traffic. Using techniques such as aggregation, cleaning, labeling, CTE, and correlation to produce recommendations on how the company can maximize revenue.                                 | Performed exploratory data analysis and joining tables to find missing data from relevant columns. Calculated the average discount for products between two brands. Performed a correlation analysis between product reviews and revenue. Used a timestamp method for calculating the volume of reviews per month. Modified a predefined CTE to filter the median revenue for unrelated products. (1st, 4th, 5th, 7th, and 9th steps of the project)                                                                                                                  | Data analysis, Aggregate functions (COUNT, SUM, corr, TRUNC, LENGTH, ROUND, AVG), Join operations (INNER JOIN), CASE clauses (WHEN, THEN), Filtering clauses (HAVING, WHERE, GROUP BY, ORDER BY, DATE_PART), Subqueries, CTE |
| Computer Vision/2023 | [YOLOv8 People Detector](https://github.com/PMenaM/Projects-en-/blob/main/YOLOv8%20People%20Detector%20(Jupyter%20Notebook)/YOLOv8%20People%20Detector%20(Jupyter%20Notebook).ipynb) | Object detection system based on the YOLO algorithm. The model was trained on a dataset consisting of images taken by drone. The images show a forest landscape with the possible presence of people to be detected by the model. A 75% - 80% of accuracy was achieved.                                                                                                                                                                               | Defined functions for comparing and sorting images and annotation files into separate folders. Defined a function for extracting file indexes from lists and moving them to specific folders. Defined a series of functions for converting files in xml format to txt and yaml. Defined a function for testing image files and saving them in a defined folder. Performed object detection in a series of images with different backgrounds.                                                                                                                        | Deep Learning, Pytorch, OpenCV, ultralytics, YOLOv8, data manipulation, data preprocessing, training, testing, Numpy, glob, os, re, shutil, yaml, pickle, xml.etree |
| NLP/2022 | [Book Recommendations from Charles Darwin](https://github.com/PMenaM/Projects-en-/blob/main/Book%20Recommendations%20from%20Charles%20Darwin%20(Jupyter%20Notebook)/Book%20Recommendations%20from%20Charles%20Darwin%20(Jupyter%20Notebook).ipynb) | NLP system for content-based book recommendation. It uses Charles Darwin's bibliography to identify books that may be of interest based on similarities to *On the Origin of Species*. The final dendrogram reflects a state-of-the-art recommendation engine.                                                                                                                               | Performed index searching to find the target text. Used list comprehensions for tokenization and removing stopwords. Performed stemming on the corpus and built a bag-of-words model. Transformed the model's result into a DataFrame, adding columns for number, index, and token. Built a tf-idf model for generating vectors and sorting them. (3rd - 9th step of the project)                                                                                                                                                                                  | Pandas, Tfidf, Matplotlib, Gensim, SciPy, glob, re, os, pickle |
| NLP/2022 | [Finding Movie Similarities from Plot Summaries](https://github.com/PMenaM/Projects-en-/tree/main/Finding%20Movie%20Similarities%20from%20Plot%20Summaries%20(Jupyter%20Notebook)) | An NLP clustering system that quantifies movie similarities based on plot summaries available on IMDb and Wikipedia. The final dendrogram reflects a state-of-the-art recommendation engine.                                                                                  | Created a filtered tokenizer object based on custom list comprehensions. Used the Snowball Stemmer algorithm for merging words with similar semantic values. Defined a function that includes the previous two steps, saving 50% of coding time and processing time. Defined a TfidfVectorizer object and used its fit-transform method to transform text into numeric vectors and remove English stopwords. (3rd - 7th step of the project)                                                                                                                             | NLTK, TfidfVectorizer, KMeans, cosine_similarity, Numpy, Pandas, Matplotlib, SciPy, linkage, dendrogram, BeautifulSoup, requests, re |


# [LinkedIn profile](https://www.linkedin.com/in/pablomenamnlp)
